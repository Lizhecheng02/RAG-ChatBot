{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNA50skr-iLU"
      },
      "outputs": [],
      "source": [
        "!pip install langchain -q\n",
        "!pip install pypdf -q\n",
        "!pip install sentence-transformers -q\n",
        "!pip install chromadb -q\n",
        "!pip install openai -q\n",
        "!pip install langchain_community -q\n",
        "!pip install llamaapi -q\n",
        "!pip install langchain_experimental -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQtbTxHZ-t1H"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from llamaapi import LlamaAPI\n",
        "from langchain_experimental.llms import ChatLlamaAPI\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEQ6Sfnf-vWf"
      },
      "outputs": [],
      "source": [
        "loader = PyPDFLoader(\"data.pdf\")\n",
        "data = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=512, chunk_overlap=128)\n",
        "texts = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrw9UYgC-2nq",
        "outputId": "c643b336-aa2a-408c-f782-091483800761"
      },
      "outputs": [],
      "source": [
        "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=embedding,\n",
        "    persist_directory=\"chroma_store\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1EeN6TT_def",
        "outputId": "dafe74be-c291-4ef9-dc0d-56ad5ae21f66"
      },
      "outputs": [],
      "source": [
        "llama = LlamaAPI(\"\") # Input your api key\n",
        "llm = ChatLlamaAPI(client=llama)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Pj7YYghcEu2Y",
        "outputId": "04feed3e-fb16-4993-8f03-e868311d41b9"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    return_source_documents=True\n",
        ")\n",
        "while True:\n",
        "    query = input()\n",
        "    if query == \"exit\":\n",
        "        break\n",
        "    result = qa({\"query\": query})\n",
        "    print(\"LLAMA:\", result[\"result\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
